{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cde6753-c327-4c1d-9ea8-63a1f851ddff",
   "metadata": {},
   "source": [
    "# Form Parsing with Gemma 3 27B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bdf36b-0ddd-4b79-9ea7-b1be3860011b",
   "metadata": {},
   "source": [
    "**objective**: Incorporate form parsing to the workflow using Gemma 3 27B\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497254a3-476d-401f-9d40-76e9a364756c",
   "metadata": {
    "height": 402
   },
   "outputs": [],
   "source": [
    "import os, json, re\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context\n",
    ")\n",
    "from helper import get_gemini_api_key, get_llama_cloud_api_key\n",
    "from IPython.display import display, HTML\n",
    "from helper import extract_html_content\n",
    "from llama_index.utils.workflow import draw_all_possible_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180fcb51-4d47-4877-a5b3-f773c64f1f72",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc3a2f78-d56f-4bbb-9664-3da5f90cf102",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "llama_cloud_api_key = get_llama_cloud_api_key()\n",
    "gemini_api_key = get_gemini_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d142d4e-48b4-43ec-ac7c-b608a8ba23c7",
   "metadata": {},
   "source": [
    "## Parsing an Application Form with LlamaParse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ada06-8cc7-4c4e-b4fb-268a0515addd",
   "metadata": {},
   "source": [
    "Let's create a parser with our new parsing instructions, including formatting instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0039610-c02e-4e7e-9c9f-1dc56450543d",
   "metadata": {
    "height": 147
   },
   "outputs": [],
   "source": [
    "parser = LlamaParse(\n",
    "    api_key=llama_cloud_api_key,\n",
    "    base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "    result_type=\"markdown\",\n",
    "    system_prompt=\"This is a job application form. Create a list of all the fields that need to be filled in. Return a bulleted list of the fields ONLY.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777454c5-31d0-4b23-ac03-f74207fbaf83",
   "metadata": {
    "height": 45
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id ece63326-668b-4364-ae04-e6c7d5283ec2\n"
     ]
    }
   ],
   "source": [
    "result = parser.load_data(\"data/fake_application_form.pdf\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4e97a9-2669-4cb9-b0ac-e42bfb14d332",
   "metadata": {},
   "source": [
    "As print out the results, you can see it has pulled all the boxes in the form and correctly turned them into field names to be filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53149fea-7383-4c39-a58c-5836857f69b7",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- First Name\n",
      "- Last Name\n",
      "- Email\n",
      "- Phone\n",
      "- Linkedin\n",
      "- Project Portfolio\n",
      "- Degree\n",
      "- Graduation Date\n",
      "- Current Job Title\n",
      "- Current Employer\n",
      "- Technical Skills\n",
      "- Describe why you’re a good fit for this position\n",
      "- Do you have 5 years of experience in React?\n"
     ]
    }
   ],
   "source": [
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b0ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear storage to force recreation with Google GenAI embeddings\n",
    "import shutil\n",
    "if os.path.exists(\"./storage\"):\n",
    "    shutil.rmtree(\"./storage\")\n",
    "    print(\"Cleared storage directory to use Google GenAI embeddings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95399d6d-1abd-4b3d-a7b1-7c9ba34e0c12",
   "metadata": {},
   "source": [
    "A useful thing LLMs can do is turn human-readable formats into machine-readable ones. You will ask the Gemma 3 27B model to turn the list into a JSON object with a list of fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d53efc82-cbd2-448d-bc6f-96d6bc1486f7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "llm = GoogleGenAI(model=\"models/gemma-3-27b-it\", api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e38ac6-1e88-46dd-ace4-77241aff9d42",
   "metadata": {
    "height": 164
   },
   "outputs": [],
   "source": [
    "raw_json = llm.complete(\n",
    "    f\"\"\"\n",
    "    This is a parsed form.\n",
    "    Convert it into a JSON object containing only the list \n",
    "    of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "    <form>{result.text}</form>. \n",
    "    Return JSON ONLY, no markdown.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe444b5-b18a-4b5b-9a9f-dd0942fff0b9",
   "metadata": {},
   "source": [
    "Here's the raw JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bc89e72-76e0-4cfd-904b-0d3dd058532b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"fields\": [\\n    \"First Name\",\\n    \"Last Name\",\\n    \"Email\",\\n    \"Phone\",\\n    \"Linkedin\",\\n    \"Project Portfolio\",\\n    \"Degree\",\\n    \"Graduation Date\",\\n    \"Current Job Title\",\\n    \"Current Employer\",\\n    \"Technical Skills\",\\n    \"Describe why you’re a good fit for this position\",\\n    \"Do you have 5 years of experience in React?\"\\n  ]\\n}\\n```'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_json.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afbf060-bed0-40a1-9173-f85eaa7e4978",
   "metadata": {},
   "source": [
    "And you can print out the fields one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5de79c4-dbda-4103-baa1-5b315af6c1e1",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Name\n",
      "Last Name\n",
      "Email\n",
      "Phone\n",
      "Linkedin\n",
      "Project Portfolio\n",
      "Degree\n",
      "Graduation Date\n",
      "Current Job Title\n",
      "Current Employer\n",
      "Technical Skills\n",
      "Describe why you’re a good fit for this position\n",
      "Do you have 5 years of experience in React?\n"
     ]
    }
   ],
   "source": [
    "# Extract JSON from markdown code blocks if present\n",
    "def extract_json_from_text(text):\n",
    "    # Try to find JSON in markdown code blocks\n",
    "    json_match = re.search(r'```(?:json)?\\s*(\\{.*?\\})\\s*```', text, re.DOTALL)\n",
    "    if json_match:\n",
    "        return json_match.group(1)\n",
    "    # If no code blocks, return the text as is\n",
    "    return text\n",
    "\n",
    "json_text = extract_json_from_text(raw_json.text)\n",
    "fields = json.loads(json_text)[\"fields\"]\n",
    "\n",
    "for field in fields:\n",
    "    print(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dabc0b2-1258-45c9-954a-67de4baca6c9",
   "metadata": {},
   "source": [
    "Now that you know how to parse the job application form, you will add this processing to the workflow of lesson 3. You will do that in two steps as shown in this figure:\n",
    "\n",
    "<img width=\"700\" src=\"images/L4-diagrams.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffc1088-2bd3-4ce8-a491-e8acd9cbde6b",
   "metadata": {},
   "source": [
    "## Adding a Form Parser to the Workflow (first update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfbb61b-8e74-45d0-ae26-d8ecc40b42c7",
   "metadata": {},
   "source": [
    "Now let's take the workflow you built in the last lesson and add your parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "436f51ba-760d-4af6-8da1-8088e7c8ebcd",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79094e64-7aa0-47d5-8974-8b3b2200d111",
   "metadata": {},
   "source": [
    "Your `set_up` step now emits a `ParseFormEvent` which triggers your new step, `parse_form`. For the moment you can leave the ask_questions step untouched, it will be updated in another section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f30a2e-2c39-411a-917c-b78549e5eef1",
   "metadata": {
    "height": 1337
   },
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    \n",
    "    storage_dir = \"./storage\"\n",
    "    llm: GoogleGenAI\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        # define the LLM to work with\n",
    "        self.llm = GoogleGenAI(model=\"models/gemma-3-27b-it\", api_key=gemini_api_key)\n",
    "\n",
    "        # ingest the data and set up the query engine\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # you've already ingested the resume document\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            # parse and load the resume document\n",
    "            documents = LlamaParse(\n",
    "                api_key=llama_cloud_api_key,\n",
    "                base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "                result_type=\"markdown\",\n",
    "                system_prompt=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume_file)\n",
    "            # embed and index the documents\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=GoogleGenAIEmbedding(model_name=\"models/text-embedding-004\", api_key=gemini_api_key)\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        # create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        # you no longer need a query to be passed in, \n",
    "        # you'll be generating the queries instead \n",
    "        # let's pass the application form to a new step to parse it\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> QueryEvent:\n",
    "        parser = LlamaParse(\n",
    "            api_key=llama_cloud_api_key,\n",
    "            base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "            result_type=\"markdown\",\n",
    "            system_prompt=\"This is a job application form. Create a list of all the fields that need to be filled in. Return a bulleted list of the fields ONLY.\"\n",
    "        )\n",
    "\n",
    "        # get the LLM to convert the parsed form into JSON\n",
    "        result = parser.load_data(ev.application_form)[0]\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"\"\"\n",
    "            This is a parsed form. \n",
    "            Convert it into a JSON object containing only the list \n",
    "            of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "            <form>{result.text}</form>. \n",
    "            Return JSON ONLY, no markdown.\n",
    "            \"\"\")\n",
    "        \n",
    "        # Extract JSON from markdown code blocks if present\n",
    "        def extract_json_from_text(text):\n",
    "            json_match = re.search(r'```(?:json)?\\s*(\\{.*?\\})\\s*```', text, re.DOTALL)\n",
    "            if json_match:\n",
    "                return json_match.group(1)\n",
    "            return text\n",
    "        \n",
    "        json_text = extract_json_from_text(raw_json.text)\n",
    "        fields = json.loads(json_text)[\"fields\"]\n",
    "\n",
    "        for field in fields:\n",
    "            print(field)\n",
    "        return StopEvent(result=\"Dummy event\")\n",
    "\n",
    "    # will be edited in the next section\n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> StopEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return StopEvent(result=response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "905709d6-ad52-4514-a75e-2bae2cfbb802",
   "metadata": {
    "height": 113
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 4e968cc5-2056-4568-9131-521b2bb5ee87\n",
      "Started parsing the file under job_id 8194f44f-79a6-4065-90fd-6b8360508b69\n",
      "First Name\n",
      "Last Name\n",
      "Email\n",
      "Phone\n",
      "Linkedin\n",
      "Project Portfolio\n",
      "Degree\n",
      "Graduation Date\n",
      "Current Job Title\n",
      "Current Employer\n",
      "Technical Skills\n",
      "Describe why you’re a good fit for this position\n",
      "Do you have 5 years of experience in React?\n"
     ]
    }
   ],
   "source": [
    "w = RAGWorkflow(timeout=60, verbose=False)\n",
    "result = await w.run(\n",
    "    resume_file=\"data/fake_resume.pdf\",\n",
    "    application_form=\"data/fake_application_form.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656e32f-19ce-4f45-883e-5c89cb800d9e",
   "metadata": {},
   "source": [
    "## Generating Questions (second update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f4a3ee-0d76-4402-9221-12dfd2755269",
   "metadata": {},
   "source": [
    "Excellent! Your workflow knows what fields it needs answers for. In this next iteration, you can fire off one `QueryEvent` for each of the fields, so they'll be executed concurrently (we talked about doing concurrent steps in Lesson 2). \n",
    "\n",
    "<img width=\"700\" src=\"images/L4-diag-2.png\">\n",
    "\n",
    "\n",
    "The changes you're going to make are:\n",
    "* Generate a `QueryEvent` for each of the questions you pulled out of the form\n",
    "* Create a `fill_in_application` step which will take all the responses to the questions and aggregate them into a coherent response\n",
    "* Add a `ResponseEvent` to pass the results of queries to `fill_in_application`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "479183ef-c912-4fb9-8b5d-348e1942e713",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str\n",
    "    field: str\n",
    "\n",
    "# new!\n",
    "class ResponseEvent(Event):\n",
    "    field: str\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a16626b-75c7-4b2f-84c5-94688530cc89",
   "metadata": {
    "height": 1864
   },
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    \n",
    "    storage_dir = \"./storage\"\n",
    "    llm: GoogleGenAI\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        # define the LLM to work with\n",
    "        self.llm = GoogleGenAI(model=\"models/gemma-3-27b-it\", api_key=gemini_api_key)\n",
    "\n",
    "        # ingest the data and set up the query engine\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # you've already ingested the resume document\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            # Force use of Google GenAI embeddings when loading from storage\n",
    "            index = load_index_from_storage(\n",
    "                storage_context,\n",
    "                embed_model=GoogleGenAIEmbedding(model_name=\"models/text-embedding-004\", api_key=gemini_api_key)\n",
    "            )\n",
    "        else:\n",
    "            # parse and load the resume document\n",
    "            documents = LlamaParse(\n",
    "                api_key=llama_cloud_api_key,\n",
    "                base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "                result_type=\"markdown\",\n",
    "                system_prompt=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume_file)\n",
    "            # embed and index the documents\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=GoogleGenAIEmbedding(model_name=\"models/text-embedding-004\", api_key=gemini_api_key)\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        # create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        # you no longer need a query to be passed in, \n",
    "        # you'll be generating the queries instead \n",
    "        # let's pass the application form to a new step to parse it\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> QueryEvent:\n",
    "        parser = LlamaParse(\n",
    "            api_key=llama_cloud_api_key,\n",
    "            base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "            result_type=\"markdown\",\n",
    "            system_prompt=\"This is a job application form. Create a list of all the fields that need to be filled in. Return a bulleted list of the fields ONLY.\"\n",
    "        )\n",
    "\n",
    "        # get the LLM to convert the parsed form into JSON\n",
    "        result = parser.load_data(ev.application_form)[0]\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"\"\"\n",
    "            This is a parsed form. \n",
    "            Convert it into a JSON object containing only the list \n",
    "            of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "            <form>{result.text}</form>. \n",
    "            Return JSON ONLY, no markdown.\n",
    "            \"\"\")\n",
    "        \n",
    "        # Extract JSON from markdown code blocks if present\n",
    "        def extract_json_from_text(text):\n",
    "            json_match = re.search(r'```(?:json)?\\s*(\\{.*?\\})\\s*```', text, re.DOTALL)\n",
    "            if json_match:\n",
    "                return json_match.group(1)\n",
    "            return text\n",
    "        \n",
    "        json_text = extract_json_from_text(raw_json.text)\n",
    "        fields = json.loads(json_text)[\"fields\"]\n",
    "\n",
    "        # new!\n",
    "        # generate one query for each of the fields, and fire them off\n",
    "        for field in fields:\n",
    "            ctx.send_event(QueryEvent(\n",
    "                field=field,\n",
    "                query=f\"How would you answer this question about the candidate? {field}\"\n",
    "            ))\n",
    "\n",
    "        # store the number of fields so we know how many to wait for later\n",
    "        await ctx.set(\"total_fields\", len(fields))\n",
    "        return\n",
    "\n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> ResponseEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return ResponseEvent(field=ev.field, response=response.response)\n",
    "\n",
    "    # new!\n",
    "    @step\n",
    "    async def fill_in_application(self, ctx: Context, ev: ResponseEvent) -> StopEvent:\n",
    "        # get the total number of fields to wait for\n",
    "        total_fields = await ctx.get(\"total_fields\")\n",
    "\n",
    "        responses = ctx.collect_events(ev, [ResponseEvent] * total_fields)\n",
    "        if responses is None:\n",
    "            return None # do nothing if there's nothing to do yet\n",
    "\n",
    "        # we've got all the responses!\n",
    "        responseList = \"\\n\".join(\"Field: \" + r.field + \"\\n\" + \"Response: \" + r.response for r in responses)\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You are given a list of fields in an application form and responses to\n",
    "            questions about those fields from a resume. Combine the two into a list of\n",
    "            fields and succinct, factual answers to fill in those fields.\n",
    "\n",
    "            <responses>\n",
    "            {responseList}\n",
    "            </responses>\n",
    "        \"\"\")\n",
    "        return StopEvent(result=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8daf0ba9-d3e7-4380-be07-368b6ec41f29",
   "metadata": {
    "height": 130
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage\\docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage\\index_store.json.\n",
      "Started parsing the file under job_id 61a4a9bc-ad83-4f10-9d57-27e62f5afc3b\n",
      "Here's a list of fields and answers, combining the application form fields with the provided resume responses:\n",
      "\n",
      "*   **First Name:** Sarah\n",
      "*   **Last Name:** Chen\n",
      "*   **Email:** sarah.chen@email.com\n",
      "*   **Phone:** sarah.chen@email.com\n",
      "*   **Linkedin:** linkedin.com/in/sarahchen\n",
      "*   **Project Portfolio:** EcoTrack (React, Node.js, MongoDB - featured in TechCrunch), ChatFlow (React, WebSocket - 5000+ MAU)\n",
      "*   **Degree:** Bachelor of Science in Computer Science (University of California, Berkeley)\n",
      "*   **Graduation Date:** 2017\n",
      "*   **Current Job Title:** Senior Full Stack Developer\n",
      "*   **Current Employer:** TechFlow Solutions (San Francisco, CA)\n",
      "*   **Technical Skills:** Vue.js, Django, React.js, Express.js, Docker, Kubernetes, AWS (EC2, S3, Lambda), Git, GitHub Actions, Jenkins, CircleCI, Agile/Scrum, Performance Optimization, Node.js, Python, GraphQL, REST APIs, PostgreSQL, MongoDB, Redux, Next.js, TypeScript, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library, WebPack, Babel.\n",
      "*   **Describe why you’re a good fit for this position:** 6+ years experience building scalable web applications & microservices. Specialization in React, Node.js, and cloud architecture. Proven leadership & CI/CD implementation.\n",
      "*   **Do you have 5 years of experience in React?** Substantial and recent React experience, including leading a product rebuild with React and related technologies.\n"
     ]
    }
   ],
   "source": [
    "w = RAGWorkflow(timeout=120, verbose=False)\n",
    "result = await w.run(\n",
    "    resume_file=\"data/fake_resume.pdf\",\n",
    "    application_form=\"data/fake_application_form.pdf\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff7243",
   "metadata": {},
   "source": [
    "## Workflow Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a1393-35b9-4fe9-a741-2dbfbeba73c9",
   "metadata": {},
   "source": [
    "You can visualize the workflow you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6416a1f-c2c9-478b-b290-8cd89998da35",
   "metadata": {
    "height": 96
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflows/form_parsing_workflow.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <div style=\"width: 100%; height: 800px; overflow: hidden;\"> <html>\n",
       "    <head>\n",
       "        <meta charset=\"utf-8\">\n",
       "        \n",
       "            <script src=\"lib/bindings/utils.js\"></script>\n",
       "            <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css\" integrity=\"sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\" />\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js\" integrity=\"sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n",
       "            \n",
       "        \n",
       "<center>\n",
       "<h1></h1>\n",
       "</center>\n",
       "\n",
       "<!-- <link rel=\"stylesheet\" href=\"../node_modules/vis/dist/vis.min.css\" type=\"text/css\" />\n",
       "<script type=\"text/javascript\" src=\"../node_modules/vis/dist/vis.js\"> </script>-->\n",
       "        <link\n",
       "          href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css\"\n",
       "          rel=\"stylesheet\"\n",
       "          integrity=\"sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        />\n",
       "        <script\n",
       "          src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js\"\n",
       "          integrity=\"sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        ></script>\n",
       "\n",
       "\n",
       "        <center>\n",
       "          <h1></h1>\n",
       "        </center>\n",
       "        <style type=\"text/css\">\n",
       "\n",
       "             #mynetwork {\n",
       "                 width: 100%;\n",
       "                 height: 750px;\n",
       "                 background-color: #ffffff;\n",
       "                 border: 1px solid lightgray;\n",
       "                 position: relative;\n",
       "                 float: left;\n",
       "             }\n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "        </style>\n",
       "    </head>\n",
       "\n",
       "\n",
       "    <body>\n",
       "        <div class=\"card\" style=\"width: 100%\">\n",
       "            \n",
       "            \n",
       "            <div id=\"mynetwork\" class=\"card-body\"></div>\n",
       "        </div>\n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        <script type=\"text/javascript\">\n",
       "\n",
       "              // initialize global variables.\n",
       "              var edges;\n",
       "              var nodes;\n",
       "              var allNodes;\n",
       "              var allEdges;\n",
       "              var nodeColors;\n",
       "              var originalNodes;\n",
       "              var network;\n",
       "              var container;\n",
       "              var options, data;\n",
       "              var filter = {\n",
       "                  item : '',\n",
       "                  property : '',\n",
       "                  value : []\n",
       "              };\n",
       "\n",
       "              \n",
       "\n",
       "              \n",
       "\n",
       "              // This method is responsible for drawing the graph, returns the drawn network\n",
       "              function drawGraph() {\n",
       "                  var container = document.getElementById('mynetwork');\n",
       "\n",
       "                  \n",
       "\n",
       "                  // parsing and collecting nodes and edges from the python\n",
       "                  nodes = new vis.DataSet([{\"color\": \"#ADD8E6\", \"id\": \"_done\", \"label\": \"_done\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#FFA07A\", \"id\": \"StopEvent\", \"label\": \"StopEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"ask_question\", \"label\": \"ask_question\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"QueryEvent\", \"label\": \"QueryEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"ResponseEvent\", \"label\": \"ResponseEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"fill_in_application\", \"label\": \"fill_in_application\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"parse_form\", \"label\": \"parse_form\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"ParseFormEvent\", \"label\": \"ParseFormEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"set_up\", \"label\": \"set_up\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#E27AFF\", \"id\": \"StartEvent\", \"label\": \"StartEvent\", \"shape\": \"ellipse\", \"title\": null}]);\n",
       "                  edges = new vis.DataSet([{\"arrows\": \"to\", \"from\": \"StopEvent\", \"to\": \"_done\"}, {\"arrows\": \"to\", \"from\": \"ask_question\", \"to\": \"ResponseEvent\"}, {\"arrows\": \"to\", \"from\": \"QueryEvent\", \"to\": \"ask_question\"}, {\"arrows\": \"to\", \"from\": \"fill_in_application\", \"to\": \"StopEvent\"}, {\"arrows\": \"to\", \"from\": \"ResponseEvent\", \"to\": \"fill_in_application\"}, {\"arrows\": \"to\", \"from\": \"parse_form\", \"to\": \"QueryEvent\"}, {\"arrows\": \"to\", \"from\": \"ParseFormEvent\", \"to\": \"parse_form\"}, {\"arrows\": \"to\", \"from\": \"set_up\", \"to\": \"ParseFormEvent\"}, {\"arrows\": \"to\", \"from\": \"StartEvent\", \"to\": \"set_up\"}]);\n",
       "\n",
       "                  nodeColors = {};\n",
       "                  allNodes = nodes.get({ returnType: \"Object\" });\n",
       "                  for (nodeId in allNodes) {\n",
       "                    nodeColors[nodeId] = allNodes[nodeId].color;\n",
       "                  }\n",
       "                  allEdges = edges.get({ returnType: \"Object\" });\n",
       "                  // adding nodes and edges to the graph\n",
       "                  data = {nodes: nodes, edges: edges};\n",
       "\n",
       "                  var options = {\n",
       "    \"configure\": {\n",
       "        \"enabled\": false\n",
       "    },\n",
       "    \"edges\": {\n",
       "        \"color\": {\n",
       "            \"inherit\": true\n",
       "        },\n",
       "        \"smooth\": {\n",
       "            \"enabled\": true,\n",
       "            \"type\": \"dynamic\"\n",
       "        }\n",
       "    },\n",
       "    \"interaction\": {\n",
       "        \"dragNodes\": true,\n",
       "        \"hideEdgesOnDrag\": false,\n",
       "        \"hideNodesOnDrag\": false\n",
       "    },\n",
       "    \"physics\": {\n",
       "        \"enabled\": true,\n",
       "        \"stabilization\": {\n",
       "            \"enabled\": true,\n",
       "            \"fit\": true,\n",
       "            \"iterations\": 1000,\n",
       "            \"onlyDynamicEdges\": false,\n",
       "            \"updateInterval\": 50\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  network = new vis.Network(container, data, options);\n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  return network;\n",
       "\n",
       "              }\n",
       "              drawGraph();\n",
       "        </script>\n",
       "    </body>\n",
       "</html> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "isolated": true
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "WORKFLOW_FILE = \"workflows/form_parsing_workflow.html\"\n",
    "draw_all_possible_flows(w, filename=WORKFLOW_FILE)\n",
    "html_content = extract_html_content(WORKFLOW_FILE)\n",
    "display(HTML(html_content), metadata=dict(isolated=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
