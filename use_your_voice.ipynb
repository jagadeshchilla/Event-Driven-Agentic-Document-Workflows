{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cde6753-c327-4c1d-9ea8-63a1f851ddff",
   "metadata": {},
   "source": [
    "# Use your voice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121aec5-1316-4186-aad5-914aecb6c6cf",
   "metadata": {},
   "source": [
    "**objective**: Get voice feedback \n",
    "\n",
    "So far we've set up a moderately complex workflow with a human feedback loop. Let's run it through the visualizer to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497254a3-476d-401f-9d40-76e9a364756c",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180fcb51-4d47-4877-a5b3-f773c64f1f72",
   "metadata": {
    "height": 557
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    "    InputRequiredEvent,\n",
    "    HumanResponseEvent\n",
    ")\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "import gradio as gr\n",
    "import asyncio\n",
    "from queue import Queue\n",
    "import vosk\n",
    "import wave\n",
    "import json as json_lib\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from helper import get_gemini_api_key, get_llama_cloud_api_key\n",
    "\n",
    "llama_cloud_api_key = get_llama_cloud_api_key()\n",
    "gemini_api_key = get_gemini_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc3a2f78-d56f-4bbb-9664-3da5f90cf102",
   "metadata": {
    "height": 2918
   },
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str\n",
    "\n",
    "class ResponseEvent(Event):\n",
    "    response: str\n",
    "\n",
    "class FeedbackEvent(Event):\n",
    "    feedback: str\n",
    "\n",
    "class GenerateQuestionsEvent(Event):\n",
    "    pass\n",
    "\n",
    "class RAGWorkflow(Workflow):\n",
    "    storage_dir = \"./storage\"\n",
    "    llm: Gemini\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        # give ourselves an LLM to work with\n",
    "        self.llm = Gemini(model=\"models/gemma-3-27b-it\", api_key=gemini_api_key)\n",
    "\n",
    "        # ingest our data and set up the query engine\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # we've already ingested our documents\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            # we need to parse and load our documents\n",
    "            documents = LlamaParse(\n",
    "                api_key=llama_cloud_api_key,\n",
    "                base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "                result_type=\"markdown\",\n",
    "                content_guideline_instruction=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume_file)\n",
    "            # embed and index the documents\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=GeminiEmbedding(model_name=\"models/text-embedding-004\", api_key=gemini_api_key)\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        # either way, create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        # let's pass our application form to a new step where we parse it\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    # we've separated the form parsing from the question generation\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> GenerateQuestionsEvent:\n",
    "        parser = LlamaParse(\n",
    "            api_key=llama_cloud_api_key,\n",
    "            base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "            result_type=\"markdown\",\n",
    "            content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\",\n",
    "            formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    "        )\n",
    "\n",
    "        # get the LLM to convert the parsed form into JSON\n",
    "        result = parser.load_data(ev.application_form)[0]\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"This is a parsed form. Convert it into a JSON object containing only the list of fields to be filled in, in the form {{ fields: [...] }}. <form>{result.text}</form>. Return JSON ONLY, no markdown.\")\n",
    "        \n",
    "        # Try to parse JSON, with error handling\n",
    "        try:\n",
    "            # Clean the response by removing markdown code blocks if present\n",
    "            json_text = raw_json.text.strip()\n",
    "            if json_text.startswith(\"```json\"):\n",
    "                json_text = json_text[7:]  # Remove ```json\n",
    "            if json_text.endswith(\"```\"):\n",
    "                json_text = json_text[:-3]  # Remove ```\n",
    "            json_text = json_text.strip()\n",
    "            \n",
    "            fields = json.loads(json_text)[\"fields\"]\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON decode error: {e}\")\n",
    "            print(f\"Raw response: '{raw_json.text}'\")\n",
    "            # Fallback: extract fields manually or use a default list\n",
    "            fields = [\n",
    "                \"First Name\", \"Last Name\", \"Email\", \"Phone\", \"Linkedin\", \n",
    "                \"Project Portfolio\", \"Degree\", \"Graduation Date\", \n",
    "                \"Current Job Title\", \"Current Employer\", \"Technical Skills\",\n",
    "                \"Describe why you're a good fit for this position\",\n",
    "                \"Do you have 5 years of experience in React?\"\n",
    "            ]\n",
    "            print(f\"Using fallback fields: {fields}\")\n",
    "\n",
    "        await ctx.set(\"fields_to_fill\", fields)\n",
    "\n",
    "        return GenerateQuestionsEvent()\n",
    "\n",
    "    # this step can get triggered either by GenerateQuestionsEvent or a FeedbackEvent\n",
    "    @step\n",
    "    async def generate_questions(self, ctx: Context, ev: GenerateQuestionsEvent | FeedbackEvent) -> QueryEvent:\n",
    "\n",
    "        # get the list of fields to fill in\n",
    "        fields = await ctx.get(\"fields_to_fill\")\n",
    "\n",
    "        # generate one query for each of the fields, and fire them off\n",
    "        for field in fields:\n",
    "            question = f\"How would you answer this question about the candidate? <field>{field}</field>\"\n",
    "\n",
    "            if hasattr(ev,\"feedback\"):\n",
    "                question += f\"\"\"\n",
    "                    \\nWe previously got feedback about how we answered the questions.\n",
    "                    It might not be relevant to this particular field, but here it is:\n",
    "                    <feedback>{ev.feedback}</feedback>\n",
    "                \"\"\"\n",
    "\n",
    "            ctx.send_event(QueryEvent(\n",
    "                field=field,\n",
    "                query=question\n",
    "            ))\n",
    "\n",
    "        # store the number of fields so we know how many to wait for later\n",
    "        await ctx.set(\"total_fields\", len(fields))\n",
    "        return\n",
    "\n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> ResponseEvent:\n",
    "        print(f\"Asking question: {ev.query}\")\n",
    "\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "\n",
    "        print(f\"Answer was: {str(response)}\")\n",
    "\n",
    "        return ResponseEvent(field=ev.field, response=response.response)\n",
    "\n",
    "    # we now emit an InputRequiredEvent\n",
    "    @step\n",
    "    async def fill_in_application(self, ctx: Context, ev: ResponseEvent) -> InputRequiredEvent:\n",
    "        # get the total number of fields to wait for\n",
    "        total_fields = await ctx.get(\"total_fields\")\n",
    "\n",
    "        responses = ctx.collect_events(ev, [ResponseEvent] * total_fields)\n",
    "        if responses is None:\n",
    "            return None # do nothing if there's nothing to do yet\n",
    "\n",
    "        # we've got all the responses!\n",
    "        responseList = \"\\n\".join(\"Field: \" + r.field + \"\\n\" + \"Response: \" + r.response for r in responses)\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You are given a list of fields in an application form and responses to\n",
    "            questions about those fields from a resume. Combine the two into a list of\n",
    "            fields and succinct, factual answers to fill in those fields.\n",
    "\n",
    "            <responses>\n",
    "            {responseList}\n",
    "            </responses>\n",
    "        \"\"\")\n",
    "\n",
    "        # save the result for later\n",
    "        await ctx.set(\"filled_form\", str(result))\n",
    "\n",
    "        # Let's get a human in the loop\n",
    "        return InputRequiredEvent(\n",
    "            prefix=\"How does this look? Give me any feedback you have on any of the answers.\",\n",
    "            result=result\n",
    "        )\n",
    "\n",
    "    # Accept the feedback.\n",
    "    @step\n",
    "    async def get_feedback(self, ctx: Context, ev: HumanResponseEvent) -> FeedbackEvent | StopEvent:\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You have received some human feedback on the form-filling task you've done.\n",
    "            Does everything look good, or is there more work to be done?\n",
    "            <feedback>\n",
    "            {ev.response}\n",
    "            </feedback>\n",
    "            If everything is fine, respond with just the word 'OKAY'.\n",
    "            If there's any other feedback, respond with just the word 'FEEDBACK'.\n",
    "        \"\"\")\n",
    "\n",
    "        verdict = result.text.strip()\n",
    "\n",
    "        print(f\"LLM says the verdict was {verdict}\")\n",
    "        if (verdict == \"OKAY\"):\n",
    "            return StopEvent(result=await ctx.get(\"filled_form\"))\n",
    "        else:\n",
    "            return FeedbackEvent(feedback=ev.response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0039610-c02e-4e7e-9c9f-1dc56450543d",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflows/lesson_6.html\n"
     ]
    }
   ],
   "source": [
    "WORKFLOW_FILE = \"workflows/lesson_6.html\"\n",
    "draw_all_possible_flows(RAGWorkflow, filename=WORKFLOW_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777454c5-31d0-4b23-ac03-f74207fbaf83",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       " <div style=\"width: 100%; height: 800px; overflow: hidden;\"> <html>\n",
       "    <head>\n",
       "        <meta charset=\"utf-8\">\n",
       "        \n",
       "            <script src=\"lib/bindings/utils.js\"></script>\n",
       "            <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css\" integrity=\"sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\" />\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js\" integrity=\"sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n",
       "            \n",
       "        \n",
       "<center>\n",
       "<h1></h1>\n",
       "</center>\n",
       "\n",
       "<!-- <link rel=\"stylesheet\" href=\"../node_modules/vis/dist/vis.min.css\" type=\"text/css\" />\n",
       "<script type=\"text/javascript\" src=\"../node_modules/vis/dist/vis.js\"> </script>-->\n",
       "        <link\n",
       "          href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css\"\n",
       "          rel=\"stylesheet\"\n",
       "          integrity=\"sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        />\n",
       "        <script\n",
       "          src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js\"\n",
       "          integrity=\"sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        ></script>\n",
       "\n",
       "\n",
       "        <center>\n",
       "          <h1></h1>\n",
       "        </center>\n",
       "        <style type=\"text/css\">\n",
       "\n",
       "             #mynetwork {\n",
       "                 width: 100%;\n",
       "                 height: 750px;\n",
       "                 background-color: #ffffff;\n",
       "                 border: 1px solid lightgray;\n",
       "                 position: relative;\n",
       "                 float: left;\n",
       "             }\n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "        </style>\n",
       "    </head>\n",
       "\n",
       "\n",
       "    <body>\n",
       "        <div class=\"card\" style=\"width: 100%\">\n",
       "            \n",
       "            \n",
       "            <div id=\"mynetwork\" class=\"card-body\"></div>\n",
       "        </div>\n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        <script type=\"text/javascript\">\n",
       "\n",
       "              // initialize global variables.\n",
       "              var edges;\n",
       "              var nodes;\n",
       "              var allNodes;\n",
       "              var allEdges;\n",
       "              var nodeColors;\n",
       "              var originalNodes;\n",
       "              var network;\n",
       "              var container;\n",
       "              var options, data;\n",
       "              var filter = {\n",
       "                  item : '',\n",
       "                  property : '',\n",
       "                  value : []\n",
       "              };\n",
       "\n",
       "              \n",
       "\n",
       "              \n",
       "\n",
       "              // This method is responsible for drawing the graph, returns the drawn network\n",
       "              function drawGraph() {\n",
       "                  var container = document.getElementById('mynetwork');\n",
       "\n",
       "                  \n",
       "\n",
       "                  // parsing and collecting nodes and edges from the python\n",
       "                  nodes = new vis.DataSet([{\"color\": \"#ADD8E6\", \"id\": \"_done\", \"label\": \"_done\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#FFA07A\", \"id\": \"StopEvent\", \"label\": \"StopEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"ask_question\", \"label\": \"ask_question\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"QueryEvent\", \"label\": \"QueryEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"ResponseEvent\", \"label\": \"ResponseEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"fill_in_application\", \"label\": \"fill_in_application\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"InputRequiredEvent\", \"label\": \"InputRequiredEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#BEDAE4\", \"id\": \"external_step\", \"label\": \"external_step\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"generate_questions\", \"label\": \"generate_questions\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"GenerateQuestionsEvent\", \"label\": \"GenerateQuestionsEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"FeedbackEvent\", \"label\": \"FeedbackEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"get_feedback\", \"label\": \"get_feedback\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"HumanResponseEvent\", \"label\": \"HumanResponseEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"parse_form\", \"label\": \"parse_form\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"ParseFormEvent\", \"label\": \"ParseFormEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"set_up\", \"label\": \"set_up\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#E27AFF\", \"id\": \"StartEvent\", \"label\": \"StartEvent\", \"shape\": \"ellipse\", \"title\": null}]);\n",
       "                  edges = new vis.DataSet([{\"arrows\": \"to\", \"from\": \"StopEvent\", \"to\": \"_done\"}, {\"arrows\": \"to\", \"from\": \"ask_question\", \"to\": \"ResponseEvent\"}, {\"arrows\": \"to\", \"from\": \"QueryEvent\", \"to\": \"ask_question\"}, {\"arrows\": \"to\", \"from\": \"fill_in_application\", \"to\": \"InputRequiredEvent\"}, {\"arrows\": \"to\", \"from\": \"InputRequiredEvent\", \"to\": \"external_step\"}, {\"arrows\": \"to\", \"from\": \"ResponseEvent\", \"to\": \"fill_in_application\"}, {\"arrows\": \"to\", \"from\": \"generate_questions\", \"to\": \"QueryEvent\"}, {\"arrows\": \"to\", \"from\": \"GenerateQuestionsEvent\", \"to\": \"generate_questions\"}, {\"arrows\": \"to\", \"from\": \"FeedbackEvent\", \"to\": \"generate_questions\"}, {\"arrows\": \"to\", \"from\": \"get_feedback\", \"to\": \"FeedbackEvent\"}, {\"arrows\": \"to\", \"from\": \"get_feedback\", \"to\": \"StopEvent\"}, {\"arrows\": \"to\", \"from\": \"HumanResponseEvent\", \"to\": \"get_feedback\"}, {\"arrows\": \"to\", \"from\": \"external_step\", \"to\": \"HumanResponseEvent\"}, {\"arrows\": \"to\", \"from\": \"parse_form\", \"to\": \"GenerateQuestionsEvent\"}, {\"arrows\": \"to\", \"from\": \"ParseFormEvent\", \"to\": \"parse_form\"}, {\"arrows\": \"to\", \"from\": \"set_up\", \"to\": \"ParseFormEvent\"}, {\"arrows\": \"to\", \"from\": \"StartEvent\", \"to\": \"set_up\"}]);\n",
       "\n",
       "                  nodeColors = {};\n",
       "                  allNodes = nodes.get({ returnType: \"Object\" });\n",
       "                  for (nodeId in allNodes) {\n",
       "                    nodeColors[nodeId] = allNodes[nodeId].color;\n",
       "                  }\n",
       "                  allEdges = edges.get({ returnType: \"Object\" });\n",
       "                  // adding nodes and edges to the graph\n",
       "                  data = {nodes: nodes, edges: edges};\n",
       "\n",
       "                  var options = {\n",
       "    \"configure\": {\n",
       "        \"enabled\": false\n",
       "    },\n",
       "    \"edges\": {\n",
       "        \"color\": {\n",
       "            \"inherit\": true\n",
       "        },\n",
       "        \"smooth\": {\n",
       "            \"enabled\": true,\n",
       "            \"type\": \"dynamic\"\n",
       "        }\n",
       "    },\n",
       "    \"interaction\": {\n",
       "        \"dragNodes\": true,\n",
       "        \"hideEdgesOnDrag\": false,\n",
       "        \"hideNodesOnDrag\": false\n",
       "    },\n",
       "    \"physics\": {\n",
       "        \"enabled\": true,\n",
       "        \"stabilization\": {\n",
       "            \"enabled\": true,\n",
       "            \"fit\": true,\n",
       "            \"iterations\": 1000,\n",
       "            \"onlyDynamicEdges\": false,\n",
       "            \"updateInterval\": 50\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  network = new vis.Network(container, data, options);\n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  return network;\n",
       "\n",
       "              }\n",
       "              drawGraph();\n",
       "        </script>\n",
       "    </body>\n",
       "</html> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "isolated": true
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, DisplayHandle\n",
    "from helper import extract_html_content\n",
    "\n",
    "html_content = extract_html_content(WORKFLOW_FILE)\n",
    "display(HTML(html_content), metadata=dict(isolated=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d55ed9-88d0-44ac-b4a3-eb605bcb0638",
   "metadata": {},
   "source": [
    "Cool! You can see the path all the way to the end and the feedback loop is clear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c82425-bdda-4f93-9226-fc4e4834d8ef",
   "metadata": {},
   "source": [
    "## Getting voice feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fad645-47db-436b-84e2-914acc89dee3",
   "metadata": {},
   "source": [
    "Now, just for fun, you'll do one more thing: change the feedback from text feedback to actual words spoken out loud. To do this we'll use VOSK, a free offline speech recognition toolkit that doesn't require any API keys.\n",
    "\n",
    "Here's a function that takes a file and uses VOSK to return just the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53149fea-7383-4c39-a58c-5836857f69b7",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "def transcribe_speech(filepath):\n",
    "    if filepath is None:\n",
    "        gr.Warning(\"No audio found, please retry.\")\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        # Download and set up VOSK model if not exists\n",
    "        import urllib.request\n",
    "        import zipfile\n",
    "        \n",
    "        model_path = \"vosk-model-small-en-us-0.15\"\n",
    "        if not os.path.exists(model_path):\n",
    "            print(\"Downloading VOSK model...\")\n",
    "            url = \"https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\"\n",
    "            urllib.request.urlretrieve(url, \"vosk-model.zip\")\n",
    "            with zipfile.ZipFile(\"vosk-model.zip\", 'r') as zip_ref:\n",
    "                zip_ref.extractall(\".\")\n",
    "            os.remove(\"vosk-model.zip\")\n",
    "            print(\"VOSK model downloaded and extracted!\")\n",
    "        \n",
    "        # Initialize VOSK model\n",
    "        model = vosk.Model(model_path)\n",
    "        rec = vosk.KaldiRecognizer(model, 16000)\n",
    "        \n",
    "        # Open audio file\n",
    "        wf = wave.open(filepath, 'rb')\n",
    "        \n",
    "        # Check if audio format is supported\n",
    "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "            print(\"Audio file must be WAV format mono PCM.\")\n",
    "            return \"\"\n",
    "        \n",
    "        results = []\n",
    "        while True:\n",
    "            data = wf.readframes(4000)\n",
    "            if len(data) == 0:\n",
    "                break\n",
    "            if rec.AcceptWaveform(data):\n",
    "                result = json_lib.loads(rec.Result())\n",
    "                if 'text' in result:\n",
    "                    results.append(result['text'])\n",
    "        \n",
    "        # Get final result\n",
    "        final_result = json_lib.loads(rec.FinalResult())\n",
    "        if 'text' in final_result:\n",
    "            results.append(final_result['text'])\n",
    "        \n",
    "        wf.close()\n",
    "        \n",
    "        # Combine all results\n",
    "        transcription = ' '.join(results).strip()\n",
    "        return transcription if transcription else \"No speech detected\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in transcription: {e}\")\n",
    "        return f\"Transcription error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b67c70a-48a6-4fcd-bf18-2c390cce5855",
   "metadata": {},
   "source": [
    "But before we can use it, you need to capture some audio from your microphone. That involves some extra steps!\n",
    "\n",
    "First, create a callback function that saves data to a global variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d53efc82-cbd2-448d-bc6f-96d6bc1486f7",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "def store_transcription(output):\n",
    "    global transcription_value\n",
    "    transcription_value = output\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389e3292-2d56-450c-bcb1-65b510a994ee",
   "metadata": {},
   "source": [
    "Now use Gradio, which has special widgets that can render inside a notebook, to create an interface for capturing audio from a microphone. When the audio is captured, it calls `transcribe_speech` on the recorded data, and calls `store_transcription` on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e38ac6-1e88-46dd-ace4-77241aff9d42",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "mic_transcribe = gr.Interface(\n",
    "    fn=lambda x: store_transcription(transcribe_speech(x)),\n",
    "    inputs=gr.Audio(sources=\"microphone\",\n",
    "                    type=\"filepath\"),\n",
    "    outputs=gr.Textbox(label=\"Transcription\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e04512-d9ab-450d-850f-072ae67bc451",
   "metadata": {},
   "source": [
    "In Gradio, you further define a visual interface containing this microphone input and output, and then launch it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc89e72-76e0-4cfd-904b-0d3dd058532b",
   "metadata": {
    "height": 217
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:8000\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:8000/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_interface = gr.Blocks()\n",
    "with test_interface:\n",
    "    gr.TabbedInterface(\n",
    "        [mic_transcribe],\n",
    "        [\"Transcribe Microphone\"]\n",
    "    )\n",
    "\n",
    "test_interface.launch(\n",
    "    share=False, \n",
    "    server_port=8000, \n",
    "    prevent_thread_lock=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30d95b-47bb-45db-9d42-5835120d92ae",
   "metadata": {},
   "source": [
    "You can now print out the transcription, which is stored in that global variable you created earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5de79c4-dbda-4103-baa1-5b315af6c1e1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(transcription_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ee4ba-f744-4b7c-906f-b26151700d27",
   "metadata": {},
   "source": [
    "You're going to want to run Gradio again, so it's a good idea to shut down the Gradio interface you were using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "436f51ba-760d-4af6-8da1-8088e7c8ebcd",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 8000\n"
     ]
    }
   ],
   "source": [
    "test_interface.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b05ec0-495f-4376-a167-43efc1db04cd",
   "metadata": {},
   "source": [
    "Now you're going to create an entirely new class, a Transcription Handler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f30a2e-2c39-411a-917c-b78549e5eef1",
   "metadata": {
    "height": 812
   },
   "outputs": [],
   "source": [
    "# New! Transcription handler.\n",
    "class TranscriptionHandler:\n",
    "\n",
    "    # we create a queue to hold transcription values\n",
    "    def __init__(self):\n",
    "        self.transcription_queue = Queue()\n",
    "        self.interface = None\n",
    "\n",
    "    # every time we record something we put it in the queue\n",
    "    def store_transcription(self, output):\n",
    "        self.transcription_queue.put(output)\n",
    "        return output\n",
    "\n",
    "    # This is the same interface and transcription logic as before\n",
    "    # except it stores the result in a queue instead of a global\n",
    "    def create_interface(self):\n",
    "        mic_transcribe = gr.Interface(\n",
    "            fn=lambda x: self.store_transcription(transcribe_speech(x)),\n",
    "            inputs=gr.Audio(sources=\"microphone\", type=\"filepath\"),\n",
    "            outputs=gr.Textbox(label=\"Transcription\")\n",
    "        )\n",
    "        self.interface = gr.Blocks()\n",
    "        with self.interface:\n",
    "            gr.TabbedInterface(\n",
    "                [mic_transcribe],\n",
    "                [\"Transcribe Microphone\"]\n",
    "            )\n",
    "        return self.interface\n",
    "\n",
    "    # we launch the transcription interface\n",
    "    async def get_transcription(self):\n",
    "        self.interface = self.create_interface()\n",
    "        self.interface.launch(\n",
    "            share=False,\n",
    "            server_port=8000, \n",
    "            prevent_thread_lock=True\n",
    "        )\n",
    "\n",
    "        # we poll every 1.5 seconds waiting for something to end up in the queue\n",
    "        while True:\n",
    "            if not self.transcription_queue.empty():\n",
    "                result = self.transcription_queue.get()\n",
    "                if self.interface is not None:\n",
    "                    self.interface.close()\n",
    "                return result\n",
    "            await asyncio.sleep(1.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07e0042-5feb-4c25-8668-33debef828a7",
   "metadata": {},
   "source": [
    "Now you have a transcription handler, you can use it instead of the keyboard input interface when you're getting human input when you run your workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "905709d6-ad52-4514-a75e-2bae2cfbb802",
   "metadata": {
    "height": 387
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: content_guideline_instruction is deprecated and may be remove in a future release. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "Started parsing the file under job_id b6c7d009-c4a5-471c-b2a7-2a910eeaa3bf\n",
      "WARNING: content_guideline_instruction is deprecated and may be remove in a future release. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "WARNING: formatting_instruction is deprecated and may be remove in a future release. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "Started parsing the file under job_id fe5146b0-839f-4ae5-b4a0-c4f05c763d3f\n",
      "Asking question: How would you answer this question about the candidate? <field>First Name</field>\n",
      "Answer was: Sarah\n",
      "Asking question: How would you answer this question about the candidate? <field>Last Name</field>\n",
      "Answer was: Chen.\n",
      "Asking question: How would you answer this question about the candidate? <field>Email</field>\n",
      "Answer was: sarah.chen@email.com\n",
      "Asking question: How would you answer this question about the candidate? <field>Phone</field>\n",
      "Answer was: This information is not available in the provided text.\n",
      "Asking question: How would you answer this question about the candidate? <field>LinkedIn</field>\n",
      "Answer was: linkedin.com/in/sarahchen\n",
      "Asking question: How would you answer this question about the candidate? <field>Project Portfolio</field>\n",
      "Answer was: The candidate has two projects listed in their portfolio: EcoTrack, a full-stack application for tracking carbon footprint built using React, Node.js, and MongoDB and featured in TechCrunch's \"Top 10 Environmental Impact Apps of 2023\", and ChatFlow, a real-time chat application developed using the WebSocket protocol and React, which serves over 5000 monthly active users.\n",
      "Asking question: How would you answer this question about the candidate? <field>Degree</field>\n",
      "Answer was: Bachelor of Science in Computer Science from University of California, Berkeley. A minor in User Experience Design was also completed.\n",
      "Asking question: How would you answer this question about the candidate? <field>Graduation Date</field>\n",
      "Answer was: 2017\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Job Title</field>\n",
      "Answer was: Senior Full Stack Developer.\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Employer</field>\n",
      "Answer was: TechFlow Solutions.\n",
      "Asking question: How would you answer this question about the candidate? <field>Technical Skills</field>\n",
      "Answer was: Frontend skills include React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library, WebPack, and Babel. Backend skills include Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, and MongoDB.\n",
      "Asking question: How would you answer this question about the candidate? <field>Describe why you’re a good fit for this position</field>\n",
      "Answer was: I am a highly innovative Full Stack Web Developer with over 6 years of experience building scalable web applications and microservices, specializing in React, Node.js, and cloud architecture. I have a history of successfully leading technical teams and implementing CI/CD pipelines, resulting in a 40% reduction in deployment time. I am dedicated to writing clean code, ensuring accessibility, and mentoring those with less experience. Additionally, I have experience architecting and implementing e-commerce platforms serving a large number of users and improving code quality through established standards and review processes.\n",
      "Asking question: How would you answer this question about the candidate? <field>Do you have 5 years of experience in React?</field>\n",
      "Answer was: The candidate has experience with React.js, Redux, Next.js, and TypeScript as frontend technologies, and has used React.js and Node.js to rebuild a flagship product while leading a team. Additionally, they developed and maintained customer-facing applications using Vue.js. This demonstrates substantial experience with JavaScript frameworks, including React.js, exceeding the five-year requirement.\n",
      "* Running on local URL:  http://127.0.0.1:8000\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:8000/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading VOSK model...\n",
      "VOSK model downloaded and extracted!\n",
      "Closing server running on port: 8000\n",
      "LLM says the verdict was FEEDBACK\n",
      "Asking question: How would you answer this question about the candidate? <field>First Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: Sarah\n",
      "Asking question: How would you answer this question about the candidate? <field>Last Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: Chen.\n",
      "Asking question: How would you answer this question about the candidate? <field>Email</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: sarah.chen@email.com\n",
      "Asking question: How would you answer this question about the candidate? <field>Phone</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: I am unable to locate a phone number within the provided information. However, the candidate’s email address is sarah.chen@email.com and their LinkedIn profile can be found at linkedin.com/in/sarahchen. Additionally, their GitHub profile is github.com/sarahcodes and portfolio at sarahchen.dev.\n",
      "Asking question: How would you answer this question about the candidate? <field>LinkedIn</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: linkedin.com/in/sarahchen\n",
      "Asking question: How would you answer this question about the candidate? <field>Project Portfolio</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: The candidate has two projects listed in their portfolio: EcoTrack, a full-stack application for tracking carbon footprint built using React, Node.js, and MongoDB and featured in TechCrunch's \"Top 10 Environmental Impact Apps of 2023\", and ChatFlow, a real-time chat application developed using the WebSocket protocol and React, which serves over 5000 monthly active users.\n",
      "Asking question: How would you answer this question about the candidate? <field>Degree</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: Bachelor of Science in Computer Science from the University of California, Berkeley, with a GPA of 3.8/4.0 and a minor in User Experience Design.\n",
      "Asking question: How would you answer this question about the candidate? <field>Graduation Date</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: 2017\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Job Title</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: Senior Full Stack Developer.\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Employer</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: TechFlow Solutions\n",
      "Asking question: How would you answer this question about the candidate? <field>Technical Skills</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: The candidate lists expertise in React.js, Redux, Next.js, TypeScript, Vue.js, and Nuxt.js for frontend development. They also have skills in HTML5, CSS3, SASS/SCSS, Jest, React Testing Library, WebPack, and Babel. \n",
      "\n",
      "For backend technologies, the candidate is proficient in Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, and MongoDB.\n",
      "Asking question: How would you answer this question about the candidate? <field>Describe why you’re a good fit for this position</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: I am a highly innovative Full Stack Web Developer with over six years of experience building scalable web applications and microservices, specializing in React, Node.js, and cloud architecture. I have a history of successfully leading technical teams and implementing CI/CD pipelines, resulting in a 40% reduction in deployment time. I am dedicated to writing clean, accessible code and enjoy mentoring junior developers. I have experience architecting and implementing large-scale platforms, like a microservices-based e-commerce platform serving over 100,000 daily users, and rebuilding flagship products with modern technologies. Additionally, I’ve improved API performance by 60% through GraphQL implementation and enhanced code quality by 45% by establishing coding standards and review processes.\n",
      "Asking question: How would you answer this question about the candidate? <field>Do you have 5 years of experience in React?</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: The individual has experience building responsive web applications with React.js and has rebuilt a flagship product using React, as well as experience with related technologies like Redux and Next.js. Additionally, they have experience developing and maintaining customer-facing applications using Vue.js. While the exact duration of React experience isn't explicitly stated as five years, the resume demonstrates substantial involvement with the technology in professional projects.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-165' coro=<_delete_state() running at c:\\Users\\Welcome\\Desktop\\ai agent\\venv\\lib\\site-packages\\gradio\\route_utils.py:935> wait_for=<Future pending cb=[Task.__wakeup()]>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:8000\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:8000/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 8000\n",
      "LLM says the verdict was FEEDBACK\n",
      "Asking question: How would you answer this question about the candidate? <field>First Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: Sarah\n",
      "Asking question: How would you answer this question about the candidate? <field>Last Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: Chen.\n",
      "Asking question: How would you answer this question about the candidate? <field>Email</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: sarah.chen@email.com\n",
      "Asking question: How would you answer this question about the candidate? <field>Phone</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: sarah.chen@email.com\n",
      "Asking question: How would you answer this question about the candidate? <field>LinkedIn</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: linkedin.com/in/sarahchen\n",
      "Asking question: How would you answer this question about the candidate? <field>Project Portfolio</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: The candidate has two projects listed in their portfolio: EcoTrack, a full-stack application for tracking carbon footprint built using React, Node.js, and MongoDB and featured in TechCrunch's \"Top 10 Environmental Impact Apps of 2023\", and ChatFlow, a real-time chat application developed using the WebSocket protocol and React, which serves over 5000 monthly active users.\n",
      "Asking question: How would you answer this question about the candidate? <field>Degree</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: Bachelor of Science in Computer Science from University of California, Berkeley.\n",
      "Asking question: How would you answer this question about the candidate? <field>Graduation Date</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: 2017\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Job Title</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: Senior Full Stack Developer.\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Employer</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: TechFlow Solutions\n",
      "Asking question: How would you answer this question about the candidate? <field>Technical Skills</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: Frontend skills include React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library, WebPack, and Babel. Backend skills include Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, and MongoDB.\n",
      "Asking question: How would you answer this question about the candidate? <field>Describe why you’re a good fit for this position</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: I am a highly innovative Full Stack Web Developer with over six years of experience building scalable web applications and microservices, specializing in React, Node.js, and cloud architecture. I have a history of successfully leading technical teams and implementing CI/CD pipelines, resulting in a 40% reduction in deployment time. I am dedicated to writing clean code, ensuring accessibility, and mentoring junior developers. I have experience architecting and implementing microservices-based platforms, rebuilding flagship products, and improving code quality through established standards and review processes. Additionally, I have a strong understanding of frontend and backend technologies, along with database management systems.\n",
      "Asking question: How would you answer this question about the candidate? <field>Do you have 5 years of experience in React?</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: The individual has experience building responsive web applications with React.js and has rebuilt a flagship product using React, as well as experience with related technologies like Redux and Next.js. Additionally, they have experience developing and maintaining customer-facing applications using Vue.js. While the resume doesn’t explicitly state 5 years of *solely* React experience, the overall experience suggests substantial proficiency.\n",
      "* Running on local URL:  http://127.0.0.1:8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-196' coro=<_delete_state() running at c:\\Users\\Welcome\\Desktop\\ai agent\\venv\\lib\\site-packages\\gradio\\route_utils.py:935> wait_for=<Future pending cb=[Task.__wakeup()]>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:8000/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 8000\n",
      "LLM says the verdict was FEEDBACK\n",
      "Asking question: How would you answer this question about the candidate? <field>First Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: Sarah\n",
      "Asking question: How would you answer this question about the candidate? <field>Last Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: Chen.\n",
      "Asking question: How would you answer this question about the candidate? <field>Email</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: sarah.chen@email.com\n",
      "Asking question: How would you answer this question about the candidate? <field>Phone</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: sarah.chen@email.com\n",
      "Asking question: How would you answer this question about the candidate? <field>LinkedIn</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: linkedin.com/in/sarahchen\n",
      "Asking question: How would you answer this question about the candidate? <field>Project Portfolio</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: The candidate has two projects listed in their portfolio: EcoTrack, a full-stack application for tracking carbon footprint built using React, Node.js, and MongoDB and featured in TechCrunch's \"Top 10 Environmental Impact Apps of 2023\", and ChatFlow, a real-time chat application developed using the WebSocket protocol and React, which serves over 5000 monthly active users.\n",
      "Asking question: How would you answer this question about the candidate? <field>Degree</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: Bachelor of Science in Computer Science from University of California, Berkeley.\n",
      "Asking question: How would you answer this question about the candidate? <field>Graduation Date</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: 2017\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Job Title</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: Senior Full Stack Developer.\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Employer</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: TechFlow Solutions.\n",
      "Asking question: How would you answer this question about the candidate? <field>Technical Skills</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: Frontend skills include React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library, WebPack, and Babel. Backend skills include Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, and MongoDB.\n",
      "Asking question: How would you answer this question about the candidate? <field>Describe why you’re a good fit for this position</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: I am a highly innovative Full Stack Web Developer with over six years of experience building scalable web applications and microservices, specializing in React, Node.js, and cloud architecture. I have a history of successfully leading technical teams and implementing CI/CD pipelines, resulting in a 40% reduction in deployment time. I am dedicated to writing clean, accessible code and enjoy mentoring junior developers. I have experience architecting and implementing large-scale platforms, like a microservices-based e-commerce platform handling over 100,000 daily users, and rebuilding flagship products with modern technologies. Additionally, I’ve improved API performance by 60% through GraphQL implementation and enhanced code quality by 45% by establishing coding standards and review processes.\n",
      "Asking question: How would you answer this question about the candidate? <field>Do you have 5 years of experience in React?</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback></feedback>\n",
      "                \n",
      "Answer was: The individual has experience building responsive web applications with React.js and has rebuilt a flagship product using React, as well as experience with related technologies like Redux and Next.js. Additionally, they have experience developing and maintaining customer-facing applications using Vue.js. While the resume doesn’t explicitly state 5 years of *solely* React experience, the overall experience suggests substantial proficiency.\n",
      "* Running on local URL:  http://127.0.0.1:8000\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:8000/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 8000\n",
      "LLM says the verdict was FEEDBACK\n",
      "Asking question: How would you answer this question about the candidate? <field>First Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: Sarah\n",
      "Asking question: How would you answer this question about the candidate? <field>Last Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: Chen.\n",
      "Asking question: How would you answer this question about the candidate? <field>Email</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: sarah.chen@email.com\n",
      "Asking question: How would you answer this question about the candidate? <field>Phone</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: I am unable to locate a phone number within the provided information. However, the candidate’s email address is sarah.chen@email.com and links to their LinkedIn and GitHub profiles are available.\n",
      "Asking question: How would you answer this question about the candidate? <field>LinkedIn</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: linkedin.com/in/sarahchen\n",
      "Asking question: How would you answer this question about the candidate? <field>Project Portfolio</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: The candidate has two projects listed in their portfolio: EcoTrack, a full-stack application for tracking carbon footprint built using React, Node.js, and MongoDB and featured in TechCrunch's \"Top 10 Environmental Impact Apps of 2023\", and ChatFlow, a real-time chat application developed using the WebSocket protocol and React, which serves over 5000 monthly active users.\n",
      "Asking question: How would you answer this question about the candidate? <field>Degree</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: Bachelor of Science in Computer Science from University of California, Berkeley, with a GPA of 3.8/4.0 and a minor in User Experience Design.\n",
      "Asking question: How would you answer this question about the candidate? <field>Graduation Date</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: 2017\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Job Title</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: Senior Full Stack Developer.\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Employer</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: TechFlow Solutions\n",
      "Asking question: How would you answer this question about the candidate? <field>Technical Skills</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: The candidate lists expertise in React.js, Redux, Next.js, TypeScript, Vue.js, and Nuxt.js for frontend development. They also have skills in HTML5, CSS3, SASS/SCSS, Jest, React Testing Library, WebPack, and Babel. \n",
      "\n",
      "For backend technologies, the candidate is proficient in Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, and MongoDB.\n",
      "Asking question: How would you answer this question about the candidate? <field>Describe why you’re a good fit for this position</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: I am a highly innovative Full Stack Web Developer with over six years of experience building scalable web applications and microservices, specializing in React, Node.js, and cloud architecture. I have a history of successfully leading technical teams and implementing CI/CD pipelines, resulting in a 40% reduction in deployment time. I am dedicated to writing clean code, ensuring accessibility, and mentoring junior developers. I have experience architecting and implementing microservices-based platforms, rebuilding flagship products, and improving code quality through established standards and review processes.\n",
      "Asking question: How would you answer this question about the candidate? <field>Do you have 5 years of experience in React?</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>No speech detected</feedback>\n",
      "                \n",
      "Answer was: The individual has experience building responsive web applications with React.js and has rebuilt a flagship product using React, as well as experience with related technologies like Redux and Next.js. Additionally, they have experience developing and maintaining customer-facing applications using Vue.js. While the exact duration of React experience isn't explicitly stated as five years, the resume demonstrates substantial involvement with the technology in professional projects.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-221' coro=<_delete_state() running at c:\\Users\\Welcome\\Desktop\\ai agent\\venv\\lib\\site-packages\\gradio\\route_utils.py:935> wait_for=<Future pending cb=[Task.__wakeup()]>>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-239' coro=<_delete_state() running at c:\\Users\\Welcome\\Desktop\\ai agent\\venv\\lib\\site-packages\\gradio\\route_utils.py:935> wait_for=<Future pending cb=[Task.__wakeup()]>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:8000\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:8000/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, InputRequiredEvent):\n\u001b[0;32m     10\u001b[0m       \u001b[38;5;66;03m# Get transcription\u001b[39;00m\n\u001b[0;32m     11\u001b[0m       transcription_handler \u001b[38;5;241m=\u001b[39m TranscriptionHandler()\n\u001b[1;32m---> 12\u001b[0m       response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m transcription_handler\u001b[38;5;241m.\u001b[39mget_transcription()\n\u001b[0;32m     14\u001b[0m       handler\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39msend_event(\n\u001b[0;32m     15\u001b[0m           HumanResponseEvent(\n\u001b[0;32m     16\u001b[0m               response\u001b[38;5;241m=\u001b[39mresponse\n\u001b[0;32m     17\u001b[0m           )\n\u001b[0;32m     18\u001b[0m       )\n\u001b[0;32m     20\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m handler\n",
      "Cell \u001b[1;32mIn[13], line 46\u001b[0m, in \u001b[0;36mTranscriptionHandler.get_transcription\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1.5\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\asyncio\\tasks.py:605\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(delay, result)\u001b[0m\n\u001b[0;32m    601\u001b[0m h \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mcall_later(delay,\n\u001b[0;32m    602\u001b[0m                     futures\u001b[38;5;241m.\u001b[39m_set_result_unless_cancelled,\n\u001b[0;32m    603\u001b[0m                     future, result)\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    607\u001b[0m     h\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\asyncio\\futures.py:285\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\asyncio\\tasks.py:304\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\asyncio\\futures.py:196\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m _CANCELLED:\n\u001b[0;32m    195\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_cancelled_error()\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m!=\u001b[39m _FINISHED:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mInvalidStateError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult is not ready.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w = RAGWorkflow(timeout=600, verbose=False)\n",
    "\n",
    "handler = w.run(\n",
    "    resume_file=\"./data/fake_resume.pdf\",\n",
    "    application_form=\"./data/fake_application_form.pdf\"\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "  if isinstance(event, InputRequiredEvent):\n",
    "      # Get transcription\n",
    "      transcription_handler = TranscriptionHandler()\n",
    "      response = await transcription_handler.get_transcription()\n",
    "\n",
    "      handler.ctx.send_event(\n",
    "          HumanResponseEvent(\n",
    "              response=response\n",
    "          )\n",
    "      )\n",
    "\n",
    "response = await handler\n",
    "print(\"Agent complete! Here's your final result:\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562cecca",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce98a735",
   "metadata": {},
   "source": [
    "To learn more about agentic document workflows, you check this [article](https://www.llamaindex.ai/blog/introducing-agentic-document-workflows) and theses [example implementations](https://github.com/run-llama/llamacloud-demo/tree/main/examples/document_workflows)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
